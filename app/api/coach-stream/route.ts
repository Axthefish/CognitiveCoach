import { NextRequest } from 'next/server';
// Ensure this route is always dynamic and not cached by Next.js
export const dynamic = 'force-dynamic';
export const revalidate = 0;
export const fetchCache = 'force-no-store';
import { CoachRequestSchema, StreamPayload } from '@/lib/schemas';
import { handleOptions, buildCorsHeaders } from '@/lib/cors';
import { buildRateKey, checkRateLimit } from '@/lib/rate-limit';
import { logger } from '@/lib/logger';
import { KnowledgeFramework, ActionPlan, FrameworkNode } from '@/lib/types';
import { createGeminiClient, generateJson, generateText } from '@/lib/gemini-config';
import {
  KnowledgeFrameworkSchema,
  SystemDynamicsSchema,
  ActionPlanResponseSchema,
  AnalyzeProgressSchema,
} from '@/lib/schemas';
import { runQualityGates } from '@/lib/qa';
import { S0Service } from '@/services/s0-service';

// æµå¼æ¶ˆæ¯ç±»å‹å®šä¹‰
interface StreamMessage {
  type: 'cognitive_step' | 'content_chunk' | 'data_structure' | 'error' | 'done';
  payload: StreamPayload;
}

// è®¤çŸ¥æ­¥éª¤çŠ¶æ€
type CognitiveStepStatus = 'pending' | 'in_progress' | 'completed' | 'error';

interface CognitiveStep {
  id: string;
  message: string;
  status: CognitiveStepStatus;
  timestamp?: number;
}

// APIè¯·æ±‚çš„actionç±»å‹
type CoachAction = 
  | 'refineGoal'
  | 'generateFramework'
  | 'generateSystemDynamics'
  | 'generateActionPlan'
  | 'analyzeProgress'
  | 'consult';

// è¯·æ±‚ä½“æ¥å£ï¼ˆå¤åˆ¶è‡ªåŸå§‹è·¯ç”±ï¼‰
type RefineGoalPayload = { userInput: string; conversationHistory?: Array<{ role: 'user' | 'assistant'; content: string }> };
type GenerateFrameworkPayload = { userGoal: string; decisionType?: string; runTier?: 'Lite'|'Pro'|'Review'; seed?: number };
type GenerateSystemDynamicsPayload = { framework: KnowledgeFramework; decisionType?: string; runTier?: 'Lite'|'Pro'|'Review'; seed?: number };
type GenerateActionPlanPayload = { userGoal: string; framework: KnowledgeFramework; systemNodes?: Array<{ id: string; title?: string }>; decisionType?: string; runTier?: 'Lite'|'Pro'|'Review'; seed?: number };
type AnalyzeProgressPayload = { progressData: { completedTasks?: string[]; confidenceScore?: number; hoursSpent?: number; challenges?: string; }; userContext: { userGoal: string; actionPlan: ActionPlan; kpis: string[]; strategySpec?: { metrics?: Array<{ metricId: string; confidence?: number; evidence?: unknown[] }> } } };
type ConsultPayload = { question: string; userContext: { userGoal: string; knowledgeFramework: KnowledgeFramework; actionPlan: ActionPlan; systemDynamics?: { mermaidChart: string; metaphor: string } } };

type CoachPayload = RefineGoalPayload | GenerateFrameworkPayload | GenerateSystemDynamicsPayload | GenerateActionPlanPayload | AnalyzeProgressPayload | ConsultPayload;

interface CoachRequest {
  action: CoachAction;
  payload: CoachPayload;
}

// æµå¼å“åº”è¾…åŠ©å‡½æ•° - ä½¿ç”¨æ ‡å‡†SSEæ ¼å¼
function createStreamMessage(type: StreamMessage['type'], payload: StreamMessage['payload']): string {
  return `data: ${JSON.stringify({ type, payload })}\n\n`;
}

// é¢„å®šä¹‰çš„è®¤çŸ¥æ­¥éª¤
const getCognitiveSteps = (action: CoachAction): CognitiveStep[] => {
  switch (action) {
    case 'generateFramework':
      return [
        { id: 'analyze-goal', message: 'æ·±å…¥åˆ†æä½ çš„å­¦ä¹ ç›®æ ‡...', status: 'pending' },
        { id: 'brainstorm-concepts', message: 'å¤´è„‘é£æš´ç›¸å…³æ¦‚å¿µå’Œé¢†åŸŸ...', status: 'pending' },
        { id: 'structure-hierarchy', message: 'æ„å»ºåˆ†å±‚çŸ¥è¯†ç»“æ„æ ‘...', status: 'pending' },
        { id: 'refine-categories', message: 'ä¼˜åŒ–ç±»åˆ«å’Œå­ä¸»é¢˜çš„æ¸…æ™°åº¦...', status: 'pending' }
      ];
    
    case 'generateSystemDynamics':
      return [
        { id: 'analyze-relationships', message: 'åˆ†æçŸ¥è¯†ç‚¹ä¹‹é—´çš„å…³ç³»...', status: 'pending' },
        { id: 'identify-sequence', message: 'è¯†åˆ«æœ€ä¼˜å­¦ä¹ åºåˆ—...', status: 'pending' },
        { id: 'craft-analogy', message: 'åˆ¶ä½œç”ŸåŠ¨çš„æ¯”å–»æ¥é˜æ˜ç³»ç»Ÿ...', status: 'pending' },
        { id: 'generate-diagram', message: 'ç”Ÿæˆ Mermaid å¯è§†åŒ–å›¾è¡¨...', status: 'pending' }
      ];
    
    case 'generateActionPlan':
      return [
        { id: 'analyze-context', message: 'åˆ†æå­¦ä¹ èƒŒæ™¯å’Œéœ€æ±‚...', status: 'pending' },
        { id: 'design-progression', message: 'è®¾è®¡æ¸è¿›å¼å­¦ä¹ è·¯å¾„...', status: 'pending' },
        { id: 'create-kpis', message: 'åˆ¶å®šå…³é”®ç»©æ•ˆæŒ‡æ ‡...', status: 'pending' },
        { id: 'optimize-plan', message: 'ä¼˜åŒ–è¡ŒåŠ¨è®¡åˆ’çš„å¯æ‰§è¡Œæ€§...', status: 'pending' }
      ];
    
    case 'analyzeProgress':
      return [
        { id: 'analyze-data', message: 'åˆ†æå­¦ä¹ è¿›åº¦æ•°æ®...', status: 'pending' },
        { id: 'identify-patterns', message: 'è¯†åˆ«å­¦ä¹ æ¨¡å¼å’Œè¶‹åŠ¿...', status: 'pending' },
        { id: 'assess-challenges', message: 'è¯„ä¼°æŒ‘æˆ˜å’Œç“¶é¢ˆ...', status: 'pending' },
        { id: 'generate-insights', message: 'ç”Ÿæˆæ´å¯Ÿå’Œå»ºè®®...', status: 'pending' }
      ];
    
    case 'refineGoal':
      return [
        { id: 'parse-input', message: 'è§£æå’Œç†è§£ä½ çš„ç›®æ ‡æè¿°...', status: 'pending' },
        { id: 'extract-intent', message: 'æŠ½å–æ ¸å¿ƒæ„å›¾å’Œå…³é”®è¦ç´ ...', status: 'pending' },
        { id: 'generate-clarification', message: 'ç”Ÿæˆç²¾å‡†çš„ç›®æ ‡è¡¨è¿°...', status: 'pending' },
        { id: 'validate-feasibility', message: 'è¯„ä¼°ç›®æ ‡çš„å¯è¡Œæ€§å’Œå®Œæ•´æ€§...', status: 'pending' }
      ];
    
    default:
      return [
        { id: 'processing', message: 'å¤„ç†ä½ çš„è¯·æ±‚...', status: 'pending' },
        { id: 'analyzing', message: 'åˆ†æè¾“å…¥å†…å®¹...', status: 'pending' },
        { id: 'generating', message: 'ç”Ÿæˆå“åº”...', status: 'pending' }
      ];
  }
};

// å¾®å­¦ä¹ æç¤º
const getMicroLearningTips = (action: CoachAction): string[] => {
  const tips = {
    refineGoal: [
      "æ¸…æ™°çš„ç›®æ ‡æ˜¯æˆåŠŸçš„ä¸€åŠï¼šSMARTåŸåˆ™å¸®ä½ æŠŠæ¨¡ç³Šæƒ³æ³•å˜æˆå…·ä½“æ–¹å‘ã€‚",
      "é—®å¯¹é—®é¢˜æ¯”æ‰¾ç­”æ¡ˆæ›´é‡è¦ï¼šæ·±å…¥æ€è€ƒ'ä¸ºä»€ä¹ˆ'èƒ½è®©ç›®æ ‡æ›´æœ‰æ„ä¹‰ã€‚",
      "ç›®æ ‡åº”è¯¥æ¿€å‘ä½ çš„çƒ­æƒ…ï¼Œè€Œä¸æ˜¯è®©ä½ æ„Ÿåˆ°å‹åŠ›ã€‚"
    ],
    generateFramework: [
      "çŸ¥è¯†æ¡†æ¶å°±åƒæ˜¯å­¦ä¹ çš„åœ°å›¾ï¼Œå®ƒèƒ½å¸®åŠ©ä½ çœ‹æ¸…å…¨è²Œï¼Œé¿å…è¿·å¤±æ–¹å‘ã€‚",
      "åˆ†å±‚å­¦ä¹ æ³•ï¼šå…ˆæŒæ¡æ ¸å¿ƒæ¦‚å¿µï¼Œå†æ·±å…¥ç»†èŠ‚ï¼Œæœ€åè¿æ¥æˆç½‘ç»œã€‚",
      "è®°ä½è´¹æ›¼æŠ€å·§ï¼šå¦‚æœä½ æ— æ³•ç”¨ç®€å•çš„è¯è§£é‡Šä¸€ä¸ªæ¦‚å¿µï¼Œè¯´æ˜ä½ è¿˜æ²¡æœ‰çœŸæ­£ç†è§£å®ƒã€‚"
    ],
    generateSystemDynamics: [
      "ç³»ç»Ÿæ€ç»´ï¼šç†è§£å„éƒ¨åˆ†å¦‚ä½•ç›¸äº’ä½œç”¨ï¼Œæ¯”å•ç‹¬å­¦ä¹ æ¯ä¸ªéƒ¨åˆ†æ›´é‡è¦ã€‚",
      "å­¦ä¹ è·¯å¾„çš„è®¾è®¡éµå¾ªè®¤çŸ¥è´Ÿè·ç†è®ºï¼šé€æ­¥å¢åŠ å¤æ‚åº¦ï¼Œé¿å…ä¿¡æ¯è¿‡è½½ã€‚",
      "å¥½çš„æ¯”å–»èƒ½è®©æŠ½è±¡æ¦‚å¿µå˜å¾—å…·ä½“ï¼Œå¤§å¤§æé«˜å­¦ä¹ æ•ˆç‡å’Œè®°å¿†æ•ˆæœã€‚"
    ],
    generateActionPlan: [
      "SMART ç›®æ ‡åŸåˆ™ï¼šå…·ä½“ã€å¯è¡¡é‡ã€å¯è¾¾æˆã€ç›¸å…³æ€§å¼ºã€æœ‰æ—¶é™ã€‚",
      "ä¹ æƒ¯å åŠ æ³•ï¼šå°†æ–°ä¹ æƒ¯é™„åŠ åœ¨å·²æœ‰ä¹ æƒ¯ä¹‹åï¼Œæ›´å®¹æ˜“åšæŒã€‚",
      "å®šæœŸå¤ç›˜å’Œè°ƒæ•´è®¡åˆ’ï¼Œçµæ´»æ€§æ˜¯æˆåŠŸå­¦ä¹ çš„å…³é”®ã€‚"
    ],
    analyzeProgress: [
      "åæ€æ˜¯å­¦ä¹ çš„åŠ é€Ÿå™¨ï¼šå®šæœŸæ€è€ƒä»€ä¹ˆæœ‰æ•ˆã€ä»€ä¹ˆéœ€è¦æ”¹è¿›ã€‚",
      "åº†ç¥å°èƒœåˆ©ï¼šè®¤å¯è¿›æ­¥èƒ½ç»´æŒå­¦ä¹ åŠ¨åŠ›ï¼Œæ— è®ºè¿›æ­¥å¤šä¹ˆå¾®å°ã€‚",
      "é—å¿˜æ›²çº¿å‘Šè¯‰æˆ‘ä»¬ï¼šåŠæ—¶å¤ä¹ æ¯”å»¶åå¤ä¹ æ•ˆç‡é«˜å¾—å¤šã€‚"
    ],
    consult: [
      "æé—®æ˜¯å­¦ä¹ çš„å‚¬åŒ–å‰‚ï¼šå¥½çš„é—®é¢˜èƒ½å¼€å¯æ–°çš„æ€ç»´è·¯å¾„ã€‚",
      "è‹æ ¼æ‹‰åº•å¼å¯¹è¯ï¼šé€šè¿‡é—®ç­”æ·±å…¥æ¢ç´¢ï¼Œæ¯”ç›´æ¥ç»™ç­”æ¡ˆæ›´æœ‰ä»·å€¼ã€‚",
      "è”ç³»å®é™…ï¼šå°†ç†è®ºçŸ¥è¯†ä¸ä¸ªäººç»éªŒè¿æ¥ï¼Œç†è§£æ›´æ·±åˆ»ã€‚"
    ]
  };
  
  return tips[action] || [
    "å­¦ä¹ æ˜¯ä¸€ä¸ªæŒç»­çš„è¿‡ç¨‹ï¼Œä¿æŒè€å¿ƒå’Œå¥½å¥‡å¿ƒæ˜¯å…³é”®ã€‚",
    "æ¯ä¸ªäººçš„å­¦ä¹ èŠ‚å¥ä¸åŒï¼Œæ‰¾åˆ°é€‚åˆè‡ªå·±çš„æ–¹æ³•æœ€é‡è¦ã€‚"
  ];
};

// ä¸»å¤„ç†å‡½æ•°
export async function POST(request: NextRequest) {
  const origin = request.headers.get('origin');
  const ip = request.headers.get('x-forwarded-for')?.split(',')[0]?.trim() || null;
  const rateKey = buildRateKey(ip, '/api/coach-stream');
  const rl = checkRateLimit(rateKey);
  
  if (!rl.allowed) {
    const encoder = new TextEncoder();
    const errorStream = createStreamMessage('error', 'Too Many Requests');
    const corsHeaders = buildCorsHeaders(origin);
    return new Response(encoder.encode(errorStream), {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache, no-store, max-age=0, must-revalidate',
        'Connection': 'keep-alive',
        'X-Accel-Buffering': 'no',
        'Retry-After': String(rl.retryAfter ?? 60),
        ...corsHeaders,
      },
      status: 429,
    });
  }

  let body: CoachRequest | undefined;
  
  try {
    const json = await request.json();
    const parsed = CoachRequestSchema.safeParse(json);
    
    if (!parsed.success) {
      const encoder = new TextEncoder();
      const errorStream = createStreamMessage('error', 'è¯·æ±‚æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·æ£€æŸ¥æ‚¨çš„è¾“å…¥å¹¶é‡è¯•');
      const corsHeaders = buildCorsHeaders(origin);
      return new Response(encoder.encode(errorStream), {
        headers: {
          'Content-Type': 'text/event-stream',
          'Cache-Control': 'no-cache, no-store, max-age=0, must-revalidate',
          'Connection': 'keep-alive',
          'X-Accel-Buffering': 'no',
          ...corsHeaders,
        },
        status: 400,
      });
    }
    
    body = parsed.data as unknown as CoachRequest;
    const { action, payload } = body;

    // åˆ›å»ºæµå¼å“åº”
    const stream = new ReadableStream({
      async start(controller) {
        const encoder = new TextEncoder();
        // ç¡®ä¿æ¯ä¸ªè¯·æ±‚åªå‘é€ä¸€æ¬¡é”™è¯¯
        const errorState = { sent: false };
        const sendErrorSafe = (
          code: 'TIMEOUT' | 'NETWORK' | 'SCHEMA' | 'QA' | 'UNKNOWN',
          message: string,
          traceId?: string
        ) => {
          if (errorState.sent) return;
          controller.enqueue(encoder.encode(createStreamMessage('error', { code, message, traceId })));
          errorState.sent = true;
        };
        
        try {
          // æ ¹æ®actionè°ƒç”¨å¯¹åº”çš„å¤„ç†å™¨
          switch (action) {
            case 'refineGoal':
              await handleRefineGoalStream(controller, encoder, payload as RefineGoalPayload);
              break;
            case 'generateFramework':
              await handleGenerateFrameworkStream(controller, encoder, payload as GenerateFrameworkPayload, sendErrorSafe);
              break;
            case 'generateSystemDynamics':
              await handleGenerateSystemDynamicsStream(controller, encoder, payload as GenerateSystemDynamicsPayload, sendErrorSafe);
              break;
            case 'generateActionPlan':
              await handleGenerateActionPlanStream(controller, encoder, payload as GenerateActionPlanPayload, sendErrorSafe);
              break;
            case 'analyzeProgress':
              await handleAnalyzeProgressStream(controller, encoder, payload as AnalyzeProgressPayload, sendErrorSafe);
              break;
            case 'consult':
              await handleConsultStream(controller, encoder, payload as ConsultPayload);
              break;
            default:
              controller.enqueue(encoder.encode(createStreamMessage('error', 'ä¸æ”¯æŒçš„æ“ä½œç±»å‹ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒ')));
          }
          
          // å‘é€å®Œæˆæ¶ˆæ¯
          controller.enqueue(encoder.encode(createStreamMessage('done', null)));
        } catch (error) {
          logger.error('Streaming API Error:', { 
            error: error instanceof Error ? error.message : String(error) 
          });
          const readableMessage = error instanceof Error ? error.message : 'Internal server error';
          
          // ğŸ’¡ æ”¹è¿›ï¼šåˆ¤æ–­é”™è¯¯ç±»å‹å¹¶å‘é€ç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
          let userFriendlyMessage = readableMessage;
          let errorCode: 'TIMEOUT' | 'NETWORK' | 'SCHEMA' | 'QA' | 'UNKNOWN' = 'UNKNOWN';
          
          if (readableMessage.includes('network') || readableMessage.includes('connection') || readableMessage.includes('fetch')) {
            errorCode = 'NETWORK';
            userFriendlyMessage = 'ç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•';
          } else if (readableMessage.includes('timeout') || readableMessage.includes('TIMEOUT')) {
            errorCode = 'TIMEOUT';
            userFriendlyMessage = 'å¤„ç†æ—¶é—´è¿‡é•¿ï¼Œæ­£åœ¨é‡æ–°å°è¯•...';
          } else if (readableMessage.includes('SCHEMA') || readableMessage.includes('schema')) {
            errorCode = 'SCHEMA';
            userFriendlyMessage = 'å†…å®¹æ ¼å¼éªŒè¯å¤±è´¥ï¼Œæ­£åœ¨é‡æ–°ç”Ÿæˆ...';
          } else if (readableMessage.includes('QA') || readableMessage.includes('quality')) {
            errorCode = 'QA';
            userFriendlyMessage = 'å†…å®¹è´¨é‡æ£€æŸ¥æœªé€šè¿‡ï¼Œæ­£åœ¨æ”¹è¿›ä¸­...';
          } else {
            userFriendlyMessage = 'å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œæ­£åœ¨å°è¯•æ¢å¤...';
          }
          
          sendErrorSafe(errorCode, userFriendlyMessage);
        } finally {
          controller.close();
        }
      },
    });

    const corsHeaders = buildCorsHeaders(origin);
    return new Response(stream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache, no-store, max-age=0, must-revalidate',
        'Connection': 'keep-alive',
        'X-Accel-Buffering': 'no',
        ...corsHeaders,
      },
    });
  } catch (error) {
    logger.error('API Error:', { 
      error: error instanceof Error ? error.message : String(error) 
    });
    const encoder = new TextEncoder();
    const readableMessage = error instanceof Error ? error.message : 'Internal server error';
    
    // åˆ¤æ–­é”™è¯¯ç±»å‹å¹¶å‘é€ç»“æ„åŒ–é”™è¯¯
    let errorCode: 'TIMEOUT' | 'NETWORK' | 'SCHEMA' | 'QA' | 'UNKNOWN' = 'UNKNOWN';
    if (readableMessage.includes('network') || readableMessage.includes('connection')) {
      errorCode = 'NETWORK';
    } else if (readableMessage.includes('timeout')) {
      errorCode = 'TIMEOUT';
    }
    
    const errorStream = createStreamMessage('error', { code: errorCode, message: readableMessage });
    const corsHeaders = buildCorsHeaders(origin);
    return new Response(encoder.encode(errorStream), {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache, no-store, max-age=0, must-revalidate',
        'Connection': 'keep-alive',
        'X-Accel-Buffering': 'no',
        ...corsHeaders,
      },
      status: 500,
    });
  }
}

export async function OPTIONS(request: NextRequest) {
  return handleOptions(request);
}

// æµå¼å¤„ç†å™¨å®ç°

async function handleRefineGoalStream(
  controller: ReadableStreamDefaultController<Uint8Array>,
  encoder: TextEncoder,
  payload: RefineGoalPayload
) {
  // S0 - Enhanced with detailed progress steps for better UX
  const steps = getCognitiveSteps('refineGoal');
  
  // å‘é€åˆå§‹æ­¥éª¤
  controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { 
    steps: steps.map(s => ({ ...s, status: 'pending' }))
  })));

  try {
    // æ­¥éª¤1ï¼šè§£æè¾“å…¥
    steps[0].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    await new Promise(resolve => setTimeout(resolve, 600));
    
    // æ­¥éª¤2ï¼šæŠ½å–æ„å›¾
    steps[0].status = 'completed';
    steps[1].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    await new Promise(resolve => setTimeout(resolve, 800));

    // æ­¥éª¤3ï¼šç”Ÿæˆæ¾„æ¸…
    steps[1].status = 'completed';
    steps[2].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    const s0Service = S0Service.getInstance();
    const result = await s0Service.refineGoal(payload);
    
    await new Promise(resolve => setTimeout(resolve, 500));
    
    // æ­¥éª¤4ï¼šéªŒè¯å¯è¡Œæ€§
    steps[2].status = 'completed';
    steps[3].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    await new Promise(resolve => setTimeout(resolve, 400));
    
    // æ‰€æœ‰æ­¥éª¤å®Œæˆ
    steps[3].status = 'completed';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    // å‘é€ç»“æœæ•°æ®
    const resultJson = await result.json();
    controller.enqueue(encoder.encode(createStreamMessage('data_structure', resultJson)));
    
  } catch (error) {
    steps.forEach(s => s.status = 'error');
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    throw error;
  }
}

async function handleGenerateFrameworkStream(
  controller: ReadableStreamDefaultController<Uint8Array>,
  encoder: TextEncoder,
  payload: GenerateFrameworkPayload,
  sendErrorSafe: (code: 'TIMEOUT' | 'NETWORK' | 'SCHEMA' | 'QA' | 'UNKNOWN', message: string, traceId?: string) => void
) {
  // ç”Ÿæˆ traceId
  const traceId = Date.now().toString(36) + '-' + Math.random().toString(36).slice(2, 6);
  
  const steps = getCognitiveSteps('generateFramework');
  const tips = getMicroLearningTips('generateFramework');
  
  // å‘é€åˆå§‹æ­¥éª¤å’Œæç¤ºï¼ˆé™„å¸¦traceIdï¼‰
  controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { 
    steps: steps.map(s => ({ ...s, status: 'pending' })),
    tip: tips[Math.floor(Math.random() * tips.length)],
    traceId
  })));

  // å¯åŠ¨å¿ƒè·³æœºåˆ¶
  const hb = setInterval(() => {
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { 
      steps, 
      tip: tips[Math.floor(Math.random() * tips.length)],
      traceId
    })));
  }, 9000);

  const genAI = createGeminiClient();
  if (!genAI) {
    sendErrorSafe('UNKNOWN', 'Gemini API key not configured', traceId);
    throw new Error('NO_API_KEY');
  }

  try {
    // æ­¥éª¤1ï¼šåˆ†æç›®æ ‡
    steps[0].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    steps[0].status = 'completed';
    steps[1].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    // æ„å»ºprompt
    const prompt = `ä½œä¸ºä¸€åä¸“ä¸šçš„æ•™è‚²ä¸“å®¶ï¼Œè¯·ä¸ºä»¥ä¸‹å­¦ä¹ ç›®æ ‡åˆ›å»ºä¸€ä¸ªç»“æ„åŒ–çš„çŸ¥è¯†æ¡†æ¶ï¼š

ç›®æ ‡ï¼š${payload.userGoal}

è¯·ç”Ÿæˆä¸€ä¸ªåˆ†å±‚çš„çŸ¥è¯†ç»“æ„ï¼ŒåŒ…å«2-3ä¸ªä¸»è¦ç±»åˆ«ï¼Œæ¯ä¸ªç±»åˆ«ä¸‹æœ‰2-4ä¸ªå­é¡¹ç›®ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼ˆä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š
[
  {
    "id": "å”¯ä¸€æ ‡è¯†ç¬¦",
    "title": "ç±»åˆ«æ ‡é¢˜",
    "summary": "ç®€çŸ­æè¿°ï¼ˆ20-40å­—ï¼‰",
    "children": [
      {
        "id": "å­é¡¹å”¯ä¸€æ ‡è¯†ç¬¦",
        "title": "å­é¡¹æ ‡é¢˜",
        "summary": "å­é¡¹æè¿°ï¼ˆ20-40å­—ï¼‰"
      }
    ],
    "evidence": [],
    "confidence": 0.6,
    "applicability": ""
  }
]

ç¡®ä¿ï¼š
1. idä½¿ç”¨è‹±æ–‡å’Œæ•°å­—çš„ç»„åˆï¼ˆå¦‚ "fundamental-concepts-1"ï¼‰
2. titleç®€æ´æ˜äº†
3. summaryæä¾›æœ‰ä»·å€¼çš„æè¿°
4. å†…å®¹ä¸å­¦ä¹ ç›®æ ‡é«˜åº¦ç›¸å…³`;

    // æ­¥éª¤2ï¼šå¤´è„‘é£æš´æ¦‚å¿µ
    await new Promise(resolve => setTimeout(resolve, 800));
    steps[1].status = 'completed';
    steps[2].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    // è°ƒç”¨AI - T3: é»˜è®¤ä½¿ç”¨ Lite æ¡£ä½
    let g = await generateJson<KnowledgeFramework>(prompt, { 
      maxOutputTokens: 65536,
      temperature: 0.8
    }, 'Lite');

    // æ£€æŸ¥æ˜¯å¦è¶…æ—¶ï¼Œå¦‚æœæ˜¯åˆ™é™çº§é‡è¯•
    if (!g.ok && g.error === 'TIMEOUT') {
      // æ¨é€é™çº§é‡è¯•çŠ¶æ€
      steps[2].status = 'in_progress';
      steps[2].message = 'æ¨¡å‹å“åº”è¶…æ—¶ï¼Œæ­£åœ¨é™çº§é‡è¯•â€¦';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
      
      // é™çº§é‡è¯•
      g = await generateJson<KnowledgeFramework>(prompt, { 
        maxOutputTokens: 65536,
        temperature: 0.4
      }, 'Lite');
      
      if (!g.ok && g.error === 'TIMEOUT') {
        sendErrorSafe('TIMEOUT', 'ç”Ÿæˆè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•');
        throw new Error('TIMEOUT');
      }
    }

    // æ­¥éª¤3ï¼šæ„å»ºç»“æ„
    await new Promise(resolve => setTimeout(resolve, 800));
    steps[2].status = 'completed';
    steps[3].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    if (!g.ok) {
      steps[3].status = 'error';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
      throw new Error('AIå“åº”è§£æå¤±è´¥');
    }

    let framework = g.data;
    const s1 = KnowledgeFrameworkSchema.safeParse(framework);
    
    if (!s1.success) {
      steps[3].status = 'error';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
      sendErrorSafe('SCHEMA', 'Schema validation failed for S1 output', traceId);
      throw new Error('SCHEMA');
    }

    // QA gate
    const qa = runQualityGates('S1', framework);
    if (!qa.passed) {
      // T3: QA failed - Pro å¤ç®—
      steps[3].status = 'in_progress';
      steps[3].message = 'QAæ£€æŸ¥æœªé€šè¿‡ï¼Œæ­£åœ¨ä½¿ç”¨ Pro æ¡£ä½å¤ç®—...';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
      
      // Pro å¤ç®—
      const gPro = await generateJson<KnowledgeFramework>(prompt, { 
        maxOutputTokens: 65536,
        temperature: 0.4
      }, 'Pro');
      
      if (!gPro.ok) {
        steps[3].status = 'error';
        controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
        sendErrorSafe('QA', 'Proå¤ç®—åä»æ— æ³•é€šè¿‡è´¨é‡æ£€æŸ¥');
        throw new Error('QA');
      }
      
      const frameworkPro = gPro.data;
      const s1Pro = KnowledgeFrameworkSchema.safeParse(frameworkPro);
      
      if (!s1Pro.success) {
        steps[3].status = 'error';
        controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
        sendErrorSafe('SCHEMA', 'Proå¤ç®—åSchemaéªŒè¯ä»å¤±è´¥', traceId);
        throw new Error('SCHEMA');
      }
      
      // ä½¿ç”¨Proç»“æœæ›´æ–°framework
      const qaPro = runQualityGates('S1', frameworkPro);
      if (!qaPro.passed) {
        steps[3].status = 'error';
        controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
        sendErrorSafe('QA', 'Proå¤ç®—åä»æ— æ³•é€šè¿‡è´¨é‡æ£€æŸ¥');
        throw new Error('QA');
      }
      
      // æ›´æ–°ä¸ºProç»“æœ
      framework = frameworkPro;
    }

    // æ­¥éª¤4ï¼šä¼˜åŒ–å®Œæˆ
    await new Promise(resolve => setTimeout(resolve, 500));
    steps[3].status = 'completed';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    // T8: è®°å½•å¯è§‚æµ‹æ€§ä¿¡æ¯
    logger.info('S1 Generation completed', {
      traceId,
      tier_used: qa.passed ? 'Lite' : 'Pro',
      qa_passed: qa.passed,
      auto_repair_applied: !qa.passed
    });

    // å‘é€æœ€ç»ˆç»“æœ
    controller.enqueue(encoder.encode(createStreamMessage('data_structure', {
      status: 'success',
      data: { framework },
      traceId
    })));
    
  } catch (error) {
    steps.forEach(s => { if (s.status === 'in_progress') s.status = 'error'; });
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    throw error;
  } finally {
    clearInterval(hb);
  }
}

async function handleGenerateSystemDynamicsStream(
  controller: ReadableStreamDefaultController<Uint8Array>,
  encoder: TextEncoder,
  payload: GenerateSystemDynamicsPayload,
  sendErrorSafe: (code: 'TIMEOUT' | 'NETWORK' | 'SCHEMA' | 'QA' | 'UNKNOWN', message: string, traceId?: string) => void
) {
  // ç”Ÿæˆ traceId
  const traceId = Date.now().toString(36) + '-' + Math.random().toString(36).slice(2, 6);
  
  const steps = getCognitiveSteps('generateSystemDynamics');
  const tips = getMicroLearningTips('generateSystemDynamics');
  
  controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { 
    steps: steps.map(s => ({ ...s, status: 'pending' })),
    tip: tips[Math.floor(Math.random() * tips.length)],
    traceId
  })));

  // å¯åŠ¨å¿ƒè·³æœºåˆ¶
  const hb = setInterval(() => {
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { 
      steps, 
      tip: tips[Math.floor(Math.random() * tips.length)],
      traceId
    })));
  }, 9000);

  const genAI = createGeminiClient();
  if (!genAI) {
    sendErrorSafe('UNKNOWN', 'Gemini API key not configured');
    throw new Error('NO_API_KEY');
  }

  try {
    // é€æ­¥å¤„ç†
    steps[0].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    
    const frameworkDescription = payload.framework.map(node => {
      const childrenDesc = node.children?.map(child => `  - ${child.title}: ${child.summary}`).join('\n') || '';
      return `${node.title}: ${node.summary}\n${childrenDesc}`;
    }).join('\n\n');
    
    await new Promise(resolve => setTimeout(resolve, 1200));
    steps[0].status = 'completed';
    steps[1].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    // Extract all S1 framework IDs for coverage requirement
    const extractFrameworkIds = (framework: KnowledgeFramework | FrameworkNode): string[] => {
      const ids: string[] = [];
      const walk = (node: FrameworkNode) => {
        if (!node || typeof node !== 'object') return;
        if (typeof node.id === 'string') ids.push(node.id);
        if (Array.isArray(node.children)) node.children.forEach(walk);
      };
      if (Array.isArray(framework)) framework.forEach(walk);
      else walk(framework);
      return ids;
    };
    
    const s1Ids = extractFrameworkIds(payload.framework);
    const s1IdsExample = s1Ids.slice(0, 2).map(id => `    { "id": "${id}", "title": "<ä¸­æ–‡åç§°æˆ–ä¸ S1 åŒæ­¥>" }`).join(',\n');

    const prompt = `åŸºäºä»¥ä¸‹çŸ¥è¯†æ¡†æ¶ï¼Œåˆ›å»ºä¸€ä¸ªç³»ç»ŸåŠ¨åŠ›å­¦å›¾è¡¨å’Œä¸€ä¸ªç”ŸåŠ¨çš„æ¯”å–»ï¼Œå¹¶è¡¥å……â€œä¸»è·¯å¾„/å…³é”®å›è·¯/èŠ‚ç‚¹ç±»æ¯”â€ï¼š

çŸ¥è¯†æ¡†æ¶ï¼š
${frameworkDescription}

è¯·å®Œæˆå…³é”®ä»»åŠ¡ï¼š

1. åˆ›å»ºä¸€ä¸ªMermaidæµç¨‹å›¾ï¼Œå±•ç¤ºè¿™äº›çŸ¥è¯†ç‚¹ä¹‹é—´çš„å…³ç³»å’Œå­¦ä¹ æµç¨‹ã€‚
2. åˆ›å»ºä¸€ä¸ªç”ŸåŠ¨å½¢è±¡çš„æ¯”å–»ï¼ˆå…¨å±€ç±»æ¯”ï¼‰ã€‚
3. **MUSTåŒ…å«nodesæ•°ç»„**ï¼šå¿…é¡»åŒ…å«æ‰€æœ‰S1æ¡†æ¶ä¸­çš„IDï¼Œä¸èƒ½é—æ¼ä»»ä½•ä¸€ä¸ªã€‚
4. æå– mainPathï¼ˆS1çš„idé¡ºåºï¼‰ã€loopsï¼ˆTop3ï¼Œå«id/title/nodes/summaryâ‰¤20å­—ï¼‰ã€nodeAnalogiesï¼ˆnodeId/1å¥ç±»æ¯”/1å¥æ—¥å¸¸ç¤ºä¾‹ï¼‰ã€‚

**CRITICAL REQUIREMENT**: nodesæ•°ç»„å¿…é¡»å®Œå…¨è¦†ç›–æ‰€æœ‰S1æ¡†æ¶IDã€‚
- IDé›†åˆå¿…é¡»å®Œå…¨ç­‰åŒäºS1æ¡†æ¶çš„idé›†åˆï¼ˆåŸæ ·ä½¿ç”¨ï¼Œä¸è¦æ ‡å‡†åŒ–ï¼‰
- ä¸å…è®¸é¢å¤–çš„ID
- å¦‚æœS1æŸä¸ªidæ²¡æœ‰æ¸…æ™°çš„æ ‡ç­¾ï¼Œè¯·å¤ç”¨å…¶idä½œä¸ºtitle

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼ˆä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š
{
  "mermaidChart": "ä»¥ graph TD å¼€å¤´çš„ Mermaid å›¾ï¼Œä¸è¦æ·»åŠ  <br/>",
  "metaphor": "ä¸€ä¸ªç”ŸåŠ¨çš„æ¯”å–»ï¼ˆ50-100å­—ï¼‰",
  "nodes": [
${s1IdsExample}
  ],
  "mainPath": ["<id1>", "<id2>"],
  "loops": [ { "id": "loop-1", "title": "<ä¸­æ–‡>", "nodes": ["<idA>","<idB>"], "summary": "<â‰¤20å­—>" } ],
  "nodeAnalogies": [ { "nodeId": "<id>", "analogy": "<1å¥ç±»æ¯”>", "example": "<1å¥æ—¥å¸¸ç¤ºä¾‹>" } ],
  "evidence": [],
  "confidence": 0.6,
  "applicability": ""
}

Mermaidå›¾è¡¨è¦æ±‚ï¼š
- ä½¿ç”¨graph TDï¼ˆä»ä¸Šåˆ°ä¸‹ï¼‰
- èŠ‚ç‚¹ä½¿ç”¨ä¸­æ–‡æ ‡ç­¾
- å±•ç¤ºå­¦ä¹ è·¯å¾„å’ŒçŸ¥è¯†ç‚¹ä¹‹é—´çš„å…³ç³»
- åŒ…å«åé¦ˆå¾ªç¯æˆ–è¿›é˜¶è·¯å¾„

æ¯”å–»è¦æ±‚ï¼š
- ä½¿ç”¨æ—¥å¸¸ç”Ÿæ´»ä¸­çš„äº‹ç‰©
- èƒ½å¤Ÿå½¢è±¡åœ°è¯´æ˜å­¦ä¹ è¿‡ç¨‹
- ä¸çŸ¥è¯†æ¡†æ¶å†…å®¹ç›¸å…³

è¯·åªè¿”å›JSONæ ¼å¼å†…å®¹ã€‚`;

    await new Promise(resolve => setTimeout(resolve, 1000));
    steps[1].status = 'completed';
    steps[2].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    // T3: é»˜è®¤ä½¿ç”¨ Lite æ¡£ä½
    let g = await generateJson<{ mermaidChart: string; metaphor: string; nodes?: Array<{ id: string; title: string }> }>(
      prompt,
      { maxOutputTokens: 65536, temperature: 0.5 },
      'Lite'
    );

    // æ£€æŸ¥æ˜¯å¦è¶…æ—¶ï¼Œå¦‚æœæ˜¯åˆ™é™çº§é‡è¯•
    if (!g.ok && g.error === 'TIMEOUT') {
      // æ¨é€é™çº§é‡è¯•çŠ¶æ€
      steps[2].status = 'in_progress';
      steps[2].message = 'æ¨¡å‹å“åº”è¶…æ—¶ï¼Œæ­£åœ¨é™çº§é‡è¯•â€¦';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
      
      // é™çº§é‡è¯•
      g = await generateJson<{ mermaidChart: string; metaphor: string; nodes?: Array<{ id: string; title: string }> }>(
        prompt,
        { maxOutputTokens: 65536, temperature: 0.4 },
        'Lite'
      );
      
      if (!g.ok && g.error === 'TIMEOUT') {
        sendErrorSafe('TIMEOUT', 'ç”Ÿæˆè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•');
        throw new Error('TIMEOUT');
      }
    }

    await new Promise(resolve => setTimeout(resolve, 800));
    steps[2].status = 'completed';
    steps[3].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    if (!g.ok) {
      steps[3].status = 'error';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
      throw new Error('AIå“åº”è§£æå¤±è´¥ï¼Œè¯·é‡è¯•');
    }

    const dynamics = g.data;
    const s2 = SystemDynamicsSchema.safeParse(dynamics);
    if (!s2.success) {
      steps[3].status = 'error';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
        sendErrorSafe('SCHEMA', 'Schema validation failed for S2 output', traceId);
      throw new Error('SCHEMA');
    }

    // Mermaid precheck and QA
    if (typeof dynamics.mermaidChart !== 'string' || !dynamics.mermaidChart.trim().startsWith('graph TD')) {
      steps[3].status = 'error';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
        sendErrorSafe('SCHEMA', 'Invalid Mermaid chart: must start with "graph TD"', traceId);
      throw new Error('SCHEMA');
    }

    // Helper function to extract nodes from framework
    function extractNodesFromFramework(fw: KnowledgeFramework): Array<{ id: string; title: string }> {
      const out: Array<{ id: string; title: string }> = [];
      const walk = (n: FrameworkNode) => {
        if (!n || typeof n !== 'object') return;
        if (typeof n.id === 'string') out.push({ id: n.id, title: typeof n.title === 'string' ? n.title : n.id });
        if (Array.isArray(n.children)) n.children.forEach(walk);
      };
      fw.forEach(walk);
      return out;
    }

    const qa = runQualityGates('S2', dynamics, { framework: payload.framework });
    if (!qa.passed) {
      // Check if any issue is a schema blocker
      const schemaBlockers = qa.issues.filter(i => i.severity === 'blocker' && i.area === 'schema');
      
      if (schemaBlockers.length > 0) {
        // Keep current behavior for schema errors
        steps[3].status = 'error';
        controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
        sendErrorSafe('SCHEMA', 'Schema validation failed', traceId);
        throw new Error('SCHEMA');
      }
      
      // Non-schema blockers or only warnings - apply auto-repair
      logger.info('S2 QA failed but non-schema, applying auto-repair', { 
        traceId,
        issueCount: qa.issues.length,
        blockerCount: qa.issues.filter(i => i.severity === 'blocker').length
      });
      
      // Derive nodes from S1 framework
      const frameworkNodes = extractNodesFromFramework(payload.framework);
      
      // Ensure dynamics.nodes exists and merge
      if (!dynamics.nodes || !Array.isArray(dynamics.nodes)) {
        dynamics.nodes = [];
      }
      
      // Create a union by id (prefer model-provided title, fallback to framework title)
      const nodeMap = new Map<string, { id: string; title: string }>();
      
      // First add framework nodes (fallback)
      frameworkNodes.forEach(node => {
        nodeMap.set(node.id, node);
      });
      
      // Then add model-provided nodes (preferred)
      dynamics.nodes.forEach(node => {
        if (node.id && node.title) {
          nodeMap.set(node.id, { id: node.id, title: node.title });
        }
      });
      
      // Update dynamics with merged nodes
      dynamics.nodes = Array.from(nodeMap.values());
      
      // Send informative message
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', {
        steps: steps.map(s => ({ ...s, status: s.status })),
        message: 'Quality gates warnings found, applying safe fallback to ensure continuity.'
      })));
      
      logger.info('S2 auto-repair completed', {
        traceId,
        derivedNodesCount: frameworkNodes.length,
        finalNodesCount: dynamics.nodes.length,
        missingResolved: frameworkNodes.length - (dynamics.nodes?.length || 0)
      });
    }

    await new Promise(resolve => setTimeout(resolve, 500));
    steps[3].status = 'completed';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    // Prepare final response with warning flags if auto-repair was applied
    const finalResponse = {
      status: 'success' as const,
      data: {
        ...dynamics,
        ...(qa.passed ? {} : {
          requiresHumanReview: true,
          qaIssues: qa.issues
        })
      }
    };

    // T8: è®°å½•S2å¯è§‚æµ‹æ€§ä¿¡æ¯  
    logger.info('S2 Generation completed', {
      traceId,
      tier_used: 'Lite',
      qa_passed: qa.passed,
      auto_repair_applied: !qa.passed
    });

    controller.enqueue(encoder.encode(createStreamMessage('data_structure', { 
      ...finalResponse, 
      traceId 
    })));
    
  } catch (error) {
    steps.forEach(s => { if (s.status === 'in_progress') s.status = 'error'; });
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    throw error;
  } finally {
    clearInterval(hb);
  }
}

async function handleGenerateActionPlanStream(
  controller: ReadableStreamDefaultController<Uint8Array>,
  encoder: TextEncoder,
  payload: GenerateActionPlanPayload,
  sendErrorSafe: (code: 'TIMEOUT' | 'NETWORK' | 'SCHEMA' | 'QA' | 'UNKNOWN', message: string, traceId?: string) => void
) {
  // ç”Ÿæˆ traceId
  const traceId = Date.now().toString(36) + '-' + Math.random().toString(36).slice(2, 6);
  
  const steps = getCognitiveSteps('generateActionPlan');
  const tips = getMicroLearningTips('generateActionPlan');
  
  controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { 
    steps: steps.map(s => ({ ...s, status: 'pending' })),
    tip: tips[Math.floor(Math.random() * tips.length)],
    traceId
  })));

  // å¯åŠ¨å¿ƒè·³æœºåˆ¶
  const hb = setInterval(() => {
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { 
      steps, 
      tip: tips[Math.floor(Math.random() * tips.length)],
      traceId
    })));
  }, 9000);

  const genAI = createGeminiClient();
  
  if (!genAI) {
    // æ¨¡æ‹Ÿå¤„ç†
    for (let i = 0; i < steps.length; i++) {
      steps[i].status = 'in_progress';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
      await new Promise(resolve => setTimeout(resolve, 1000 + Math.random() * 1000));
      steps[i].status = 'completed';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    }

    const mockActionPlan: ActionPlan = [
      {
        id: 'action-1',
        text: 'å®ŒæˆåŸºç¡€æ¦‚å¿µå­¦ä¹ ï¼šé˜…è¯»æ¨èèµ„æ–™ï¼Œåšç¬”è®°æ€»ç»“',
        isCompleted: false
      },
      {
        id: 'action-2',
        text: 'æ­å»ºå¼€å‘ç¯å¢ƒï¼šå®‰è£…å¿…è¦å·¥å…·å’Œé…ç½®',
        isCompleted: false
      }
    ];
    
    const mockKPIs = [
      'æ¯å‘¨å­¦ä¹ æ—¶é—´ï¼ˆå°æ—¶ï¼‰',
      'å®Œæˆçš„ç»ƒä¹ é¡¹ç›®æ•°'
    ];
    
    controller.enqueue(encoder.encode(createStreamMessage('data_structure', {
      status: 'success',
      data: {
        actionPlan: mockActionPlan,
        kpis: mockKPIs
      }
    })));
    return;
  }

  try {
    // æ¸è¿›å¼å¤„ç†æ­¥éª¤
    steps[0].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    
    const frameworkDescription = payload.framework.map(node => {
      const childrenDesc = node.children?.map(child => `  - ${child.title}: ${child.summary}`).join('\n') || '';
      return `${node.title}: ${node.summary}\n${childrenDesc}`;
    }).join('\n\n');
    
    await new Promise(resolve => setTimeout(resolve, 1200));
    steps[0].status = 'completed';
    steps[1].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    const prompt = `ä½œä¸ºä¸€åä¸“ä¸šçš„å­¦ä¹ è§„åˆ’ä¸“å®¶ï¼ŒåŸºäºä»¥ä¸‹å­¦ä¹ ç›®æ ‡å’ŒçŸ¥è¯†æ¡†æ¶ï¼Œä¸ºå­¦ä¹ è€…åˆ›å»ºä¸€ä¸ªä¸ªæ€§åŒ–çš„è¡ŒåŠ¨è®¡åˆ’ã€‚

å­¦ä¹ ç›®æ ‡ï¼š${payload.userGoal}

çŸ¥è¯†æ¡†æ¶ï¼š
${frameworkDescription}

è¯·å®Œæˆä¸¤ä¸ªä»»åŠ¡ï¼š

1. åˆ›å»ºä¸€ä¸ªå…·ä½“ã€å¯æ‰§è¡Œçš„è¡ŒåŠ¨è®¡åˆ’ï¼ˆ5-8ä¸ªæ­¥éª¤ï¼‰
2. è®¾è®¡3-5ä¸ªå…³é”®ç»©æ•ˆæŒ‡æ ‡ï¼ˆKPIsï¼‰æ¥è·Ÿè¸ªå­¦ä¹ è¿›åº¦

è¦æ±‚ï¼š
- è¡ŒåŠ¨è®¡åˆ’åº”è¯¥å¾ªåºæ¸è¿›ï¼Œä»åŸºç¡€åˆ°é«˜çº§
- æ¯ä¸ªæ­¥éª¤éƒ½åº”è¯¥å…·ä½“ä¸”å¯æ‰§è¡Œ
- æ­¥éª¤åº”è¯¥ä¸çŸ¥è¯†æ¡†æ¶ç´§å¯†ç›¸å…³
- ä½¿ç”¨ç¬¬ä¸€äººç§°ï¼ˆ"æˆ‘"ï¼‰æ¥æè¿°è¡ŒåŠ¨æ­¥éª¤
- KPIsåº”è¯¥å¯é‡åŒ–æˆ–å¯è¯„ä¼°

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼ˆä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š
{
  "actionPlan": [
    {
      "id": "step-1",
      "text": "å…·ä½“çš„è¡ŒåŠ¨æ­¥éª¤æè¿°",
      "isCompleted": false
    }
  ],
  "kpis": [
    "KPIæè¿°1",
    "KPIæè¿°2"
  ]
}

æ³¨æ„ï¼šä¸ºäº†ç¡®ä¿ç”ŸæˆæˆåŠŸï¼Œè¯·åªè¿”å› actionPlan å’Œ kpis ä¸¤ä¸ªå­—æ®µã€‚
å¦‚æœéœ€è¦é«˜çº§ç­–ç•¥é…ç½®ï¼Œç³»ç»Ÿä¼šåœ¨åç»­æ­¥éª¤ä¸­å•ç‹¬å¤„ç†ã€‚

ç¡®ä¿ï¼š
1. idä½¿ç”¨ "step-1", "step-2" ç­‰æ ¼å¼
2. textæ˜¯å…·ä½“çš„è¡ŒåŠ¨æè¿°ï¼ˆ20-50å­—ï¼‰
3. æ‰€æœ‰isCompletedéƒ½è®¾ä¸ºfalse
4. KPIsç®€æ´æ˜äº†ï¼ˆ10-20å­—ï¼‰`;

    await new Promise(resolve => setTimeout(resolve, 1000));
    steps[1].status = 'completed';
    steps[2].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    // T3: å…ˆç”¨ Lite ç”Ÿæˆ 1 ä¸ªæ–¹æ¡ˆ
    const variants = [] as Array<{ text: string; qaScore: number; issues: string[] }>;
    const n = 1; // å›ºå®šä¸º1ï¼Œå¦‚éœ€è¦ä¼šåœ¨åç»­æ·»åŠ Proæ–¹æ¡ˆ
    
    for (let i = 0; i < n; i++) {
      const r = await generateJson<Record<string, unknown>>(prompt, { 
        maxOutputTokens: 65536, 
        temperature: 0.5 
      }, 'Lite');
      
      if (!r.ok && r.error === 'TIMEOUT') {
        // æ¨é€é™çº§é‡è¯•çŠ¶æ€
        steps[2].status = 'in_progress';
        steps[2].message = 'æ¨¡å‹å“åº”è¶…æ—¶ï¼Œæ­£åœ¨é™çº§é‡è¯•â€¦';
        controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
        
        // é™çº§é‡è¯•
        const retryR = await generateJson<Record<string, unknown>>(prompt, { 
          maxOutputTokens: 65536, 
          temperature: 0.4 
        }, 'Lite');
        
        if (!retryR.ok && retryR.error === 'TIMEOUT') {
          sendErrorSafe('TIMEOUT', 'ç”Ÿæˆè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•');
          throw new Error('TIMEOUT');
        }
        
        const text = retryR.ok ? JSON.stringify(retryR.data) : '';
        variants.push({ text, qaScore: 0, issues: [] });
        break; // é™çº§é‡è¯•æˆåŠŸåé€€å‡ºå¾ªç¯
      } else {
        const text = r.ok ? JSON.stringify(r.data) : '';
        variants.push({ text, qaScore: 0, issues: [] });
      }
    }

    await new Promise(resolve => setTimeout(resolve, 1000));
    steps[2].status = 'completed';
    steps[3].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    // Evaluate variants
    let best: unknown | null = null;
    let bestIssuesCount = Number.POSITIVE_INFINITY;
    for (const v of variants) {
      try {
        const planData = JSON.parse(v.text);
        const s3 = ActionPlanResponseSchema.safeParse(planData);
        if (!s3.success) {
          v.issues = ['schema'];
          continue;
        }
        const qa = runQualityGates('S3', planData, { nodes: (payload.systemNodes || []).map(n => ({ id: n.id })) });
        v.issues = qa.issues.map(issue => issue.hint || 'Quality issue');
        if (qa.passed) {
          const issueCount = qa.issues.length;
          if (issueCount < bestIssuesCount) {
            best = planData;
            bestIssuesCount = issueCount;
          }
        }
      } catch (parseError) {
        logger.error('JSON parsing failed during action plan generation:', parseError);
        v.issues = ['parse'];
      }
    }

    // T3: å¦‚æœLiteæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„æ–¹æ¡ˆï¼Œå°è¯•Proå¤ç®—
    if (!best) {
      steps[3].status = 'in_progress';
      steps[3].message = 'Liteæ–¹æ¡ˆè´¨é‡ä¸è¶³ï¼Œæ­£åœ¨ä½¿ç”¨ Pro æ¡£ä½ç”Ÿæˆå¯¹ç…§æ–¹æ¡ˆ...';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
      
      // ç”¨Proç”Ÿæˆä¸€ä¸ªå¯¹ç…§æ–¹æ¡ˆ
      const rPro = await generateJson<Record<string, unknown>>(prompt, { 
        maxOutputTokens: 65536, 
        temperature: 0.8 
      }, 'Pro');
      
      if (rPro.ok) {
        const textPro = JSON.stringify(rPro.data);
        variants.push({ text: textPro, qaScore: 0, issues: [] });
        
        // é‡æ–°è¯„ä¼°åŒ…æ‹¬Proæ–¹æ¡ˆçš„æ‰€æœ‰å˜ä½“
        for (const v of variants) {
          try {
            const planData = JSON.parse(v.text);
            const s3 = ActionPlanResponseSchema.safeParse(planData);
            if (!s3.success) {
              v.issues = ['schema'];
              continue;
            }
            const qa = runQualityGates('S3', planData, { nodes: (payload.systemNodes || []).map(n => ({ id: n.id })) });
            v.issues = qa.issues.map(issue => issue.hint || 'Quality issue');
            if (qa.passed) {
              const issueCount = qa.issues.length;
              if (!best || issueCount < bestIssuesCount) {
                best = planData;
                bestIssuesCount = issueCount;
              }
            }
          } catch (parseError) {
            logger.error('JSON parsing failed during Pro recalc:', parseError);
            v.issues = ['parse'];
          }
        }
      }
    }

    if (best) {
      await new Promise(resolve => setTimeout(resolve, 500));
      steps[3].status = 'completed';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

      const povTags = ['maximize_gain', 'minimize_risk'];
      const requiresHumanReview = Array.isArray((best as { strategySpec?: { metrics?: Array<{ confidence?: number; evidence?: unknown[] }> } }).strategySpec?.metrics)
        && ((((best as { strategySpec?: { metrics?: Array<{ confidence?: number; evidence?: unknown[] }> } }).strategySpec)?.metrics) || [])
          .some((m) => ((m.confidence ?? 1) < 0.4) || !m.evidence || ((m.evidence as unknown[])?.length ?? 0) === 0);
      const telemetry = { n_best_count: variants.length };
      
      // T8: è®°å½•S3å¯è§‚æµ‹æ€§ä¿¡æ¯
      logger.info('S3 Generation completed', {
        traceId,
        tier_used: variants.length > 1 ? 'Lite+Pro' : 'Lite',
        qa_passed: true,
        auto_repair_applied: false,
        n_best_count: variants.length
      });

      controller.enqueue(encoder.encode(createStreamMessage('data_structure', {
        status: 'success', 
        data: { ...(best as object), povTags, requiresHumanReview, telemetry },
        traceId
      })));
      return;
    }

    // Final attempt with lower temperature using Lite first
    const retryR = await generateJson<Record<string, unknown>>(prompt, { 
      temperature: 0.4, topK: 40, topP: 0.9, maxOutputTokens: 65536 
    }, 'Lite');
    const retryText = retryR.ok ? JSON.stringify(retryR.data) : '';
    
    const planData = JSON.parse(retryText);
    const enrichedPlanData = {
      ...planData,
      strategySpec: planData.strategySpec || null,
      missingEvidenceTop3: planData.missingEvidenceTop3 || [],
      reviewWindow: planData.reviewWindow || "P14D",
      evidence: planData.evidence || [],
      confidence: planData.confidence || 0.6,
      applicability: planData.applicability || ""
    };
    
    const s3 = ActionPlanResponseSchema.safeParse(enrichedPlanData);
    if (!s3.success) {
      sendErrorSafe('SCHEMA', 'Schema validation failed for S3 output', traceId);
      throw new Error('SCHEMA');
    }
    
    const qa = runQualityGates('S3', planData, { nodes: (payload.systemNodes || []).map(n => ({ id: n.id })) });
    if (!qa.passed) {
      sendErrorSafe('QA', 'Quality gates failed', traceId);
      throw new Error('QA');
    }
    
    await new Promise(resolve => setTimeout(resolve, 500));
    steps[3].status = 'completed';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    const povTags = ['maximize_gain', 'minimize_risk'];
    const requiresHumanReview = Array.isArray(planData.strategySpec?.metrics)
      && ((planData.strategySpec?.metrics) || [])
        .some((m: { confidence?: number; evidence?: unknown[] }) => ((m.confidence ?? 1) < 0.4) || !m.evidence || ((m.evidence as unknown[])?.length ?? 0) === 0);
    const telemetry = { n_best_count: 1, retry: true };
    
    // T8: è®°å½•S3 fallbackå¯è§‚æµ‹æ€§ä¿¡æ¯
    logger.info('S3 Fallback Generation completed', {
      traceId,
      tier_used: 'Lite',
      qa_passed: true,
      auto_repair_applied: false,
      retry: true
    });

    controller.enqueue(encoder.encode(createStreamMessage('data_structure', {
      status: 'success', 
      data: { ...planData, povTags, requiresHumanReview, telemetry },
      traceId
    })));
    
  } catch (error) {
    steps.forEach(s => { if (s.status === 'in_progress') s.status = 'error'; });
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    throw error;
  } finally {
    clearInterval(hb);
  }
}

async function handleAnalyzeProgressStream(
  controller: ReadableStreamDefaultController<Uint8Array>,
  encoder: TextEncoder,
  payload: AnalyzeProgressPayload,
  sendErrorSafe: (code: 'TIMEOUT' | 'NETWORK' | 'SCHEMA' | 'QA' | 'UNKNOWN', message: string, traceId?: string) => void
) {
  // ç”Ÿæˆ traceId
  const traceId = Date.now().toString(36) + '-' + Math.random().toString(36).slice(2, 6);
  
  const steps = getCognitiveSteps('analyzeProgress');
  const tips = getMicroLearningTips('analyzeProgress');
  
  controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { 
    steps: steps.map(s => ({ ...s, status: 'pending' })),
    tip: tips[Math.floor(Math.random() * tips.length)],
    traceId
  })));

  // å¯åŠ¨å¿ƒè·³æœºåˆ¶
  const hb = setInterval(() => {
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { 
      steps, 
      tip: tips[Math.floor(Math.random() * tips.length)],
      traceId
    })));
  }, 9000);

  const genAI = createGeminiClient();
  
  if (!genAI) {
    // æ¨¡æ‹Ÿå¤„ç†
    for (let i = 0; i < steps.length; i++) {
      steps[i].status = 'in_progress';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
      await new Promise(resolve => setTimeout(resolve, 800 + Math.random() * 800));
      steps[i].status = 'completed';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    }

    const analysis = 'åŸºäºæ‚¨çš„æ•°æ®ï¼Œæ‚¨åœ¨ç†è®ºå­¦ä¹ æ–¹é¢è¿›å±•è‰¯å¥½ï¼Œä½†å®è·µåº”ç”¨è¿˜éœ€è¦åŠ å¼ºã€‚å»ºè®®å¢åŠ åŠ¨æ‰‹ç»ƒä¹ çš„æ—¶é—´ã€‚';
    
    controller.enqueue(encoder.encode(createStreamMessage('data_structure', {
      status: 'success',
      data: {
        analysis,
        suggestions: ['å¢åŠ å®è·µæ—¶é—´', 'å¯»æ‰¾å®é™…é¡¹ç›®æœºä¼š', 'ä¸ä»–äººäº¤æµå­¦ä¹ ç»éªŒ']
      }
    })));
    return;
  }

  try {
    // é€æ­¥åˆ†æ
    steps[0].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    
    const completedTasksCount = payload.progressData.completedTasks?.length || 0;
    const totalTasksCount = payload.userContext.actionPlan?.length || 0;
    const completionRate = totalTasksCount > 0 ? Math.round((completedTasksCount / totalTasksCount) * 100) : 0;
    
    await new Promise(resolve => setTimeout(resolve, 1000));
    steps[0].status = 'completed';
    steps[1].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    const prompt = `ä½œä¸ºä¸€åä¸“ä¸šçš„å­¦ä¹ æ•™ç»ƒï¼ŒåŸºäºä»¥ä¸‹å­¦ä¹ è¿›åº¦æ•°æ®ï¼Œæä¾›æ·±å…¥çš„åˆ†æå’Œå»ºè®®ã€‚è¯·å°½é‡å¼•ç”¨ S3 çš„ç­–ç•¥æŒ‡æ ‡ï¼ˆmetrics.metricIdï¼‰ä¸å¤è¯„æŒ‡æ ‡ï¼ˆrecovery.reviewMetricIdsï¼‰è¿›è¡Œå‚è€ƒã€‚

å­¦ä¹ ç›®æ ‡ï¼š${payload.userContext.userGoal}

è¿›åº¦æ•°æ®ï¼š
- ä»»åŠ¡å®Œæˆç‡ï¼š${completionRate}% (${completedTasksCount}/${totalTasksCount})
- è‡ªè¯„ä¿¡å¿ƒåˆ†æ•°ï¼š${payload.progressData.confidenceScore || 'æœªæä¾›'}/10
- å·²æŠ•å…¥æ—¶é—´ï¼š${payload.progressData.hoursSpent || 'æœªæä¾›'}å°æ—¶
- é‡åˆ°çš„æŒ‘æˆ˜ï¼š${payload.progressData.challenges || 'æœªæä¾›'}

å…³é”®ç»©æ•ˆæŒ‡æ ‡ï¼ˆKPIsï¼‰ï¼š
${payload.userContext.kpis?.join('\n') || 'æ— '}

è¯·æä¾›ï¼š
1. å¯¹å½“å‰å­¦ä¹ è¿›åº¦çš„åˆ†æï¼ˆè€ƒè™‘å®Œæˆç‡ã€ä¿¡å¿ƒæ°´å¹³ã€æ—¶é—´æŠ•å…¥ç­‰ï¼‰
2. è¯†åˆ«æ½œåœ¨çš„é—®é¢˜æˆ–ç“¶é¢ˆ
3. 3-5ä¸ªå…·ä½“ã€å¯æ‰§è¡Œçš„æ”¹è¿›å»ºè®®

è¦æ±‚ï¼š
- åˆ†æè¦å…·ä½“ä¸”æœ‰æ´å¯ŸåŠ›
- å»ºè®®è¦å®ç”¨ä¸”é’ˆå¯¹æ€§å¼º
- è¯­æ°”è¦é¼“åŠ±å’Œæ”¯æŒ
- ä½¿ç”¨ç®€ä½“ä¸­æ–‡

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼ˆä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š
{
  "analysis": "è¯¦ç»†çš„è¿›åº¦åˆ†æï¼ˆ100-200å­—ï¼‰",
  "suggestions": [
    "å…·ä½“å»ºè®®1",
    "å…·ä½“å»ºè®®2",
    "å…·ä½“å»ºè®®3"
  ],
  "encouragement": "é¼“åŠ±æ€§çš„ç»“è¯­ï¼ˆ30-50å­—ï¼‰",
  "referencedMetricIds": [],
  "evidence": [],
  "confidence": 0.6,
  "applicability": ""
}`;

    await new Promise(resolve => setTimeout(resolve, 1000));
    steps[1].status = 'completed';
    steps[2].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    // T3: S4é»˜è®¤ä½¿ç”¨ Lite
    let g = await generateJson<Record<string, unknown>>(prompt, { maxOutputTokens: 65536 }, 'Lite');

    // æ£€æŸ¥æ˜¯å¦è¶…æ—¶ï¼Œå¦‚æœæ˜¯åˆ™é™çº§é‡è¯•
    if (!g.ok && g.error === 'TIMEOUT') {
      // æ¨é€é™çº§é‡è¯•çŠ¶æ€
      steps[2].status = 'in_progress';
      steps[2].message = 'æ¨¡å‹å“åº”è¶…æ—¶ï¼Œæ­£åœ¨é™çº§é‡è¯•â€¦';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
      
      // é™çº§é‡è¯•
      g = await generateJson<Record<string, unknown>>(prompt, { 
        maxOutputTokens: 65536, 
        temperature: 0.4 
      }, 'Lite');
      
      if (!g.ok && g.error === 'TIMEOUT') {
        sendErrorSafe('TIMEOUT', 'ç”Ÿæˆè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•');
        throw new Error('TIMEOUT');
      }
    }

    await new Promise(resolve => setTimeout(resolve, 800));
    steps[2].status = 'completed';
    steps[3].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    if (!g.ok) {
      steps[3].status = 'error';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
      const errorMessage = g.error === 'EMPTY_RESPONSE' 
        ? 'æŠ±æ­‰ï¼ŒAIæš‚æ—¶æ— æ³•åˆ†ææ‚¨çš„è¿›åº¦ã€‚è¯·ç¨åé‡è¯•ã€‚'
        : 'è¿›åº¦åˆ†æé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ•°æ®å¹¶é‡è¯•ã€‚';
      throw new Error(errorMessage);
    }

    let analysisData = g.data;
    const s4 = AnalyzeProgressSchema.safeParse(analysisData);
    if (!s4.success) {
      steps[3].status = 'error';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
      sendErrorSafe('SCHEMA', 'Schema validation failed for S4 output', traceId);
      throw new Error('SCHEMA');
    }

    // QA S3->S4 linkage
    const s4qa = runQualityGates('S4', analysisData, { strategyMetrics: payload.userContext.strategySpec?.metrics || [] });
    if (!s4qa.passed) {
      // T3: S4 QAå¤±è´¥æ—¶ï¼Œä½¿ç”¨Proè¿›è¡Œæ·±åº¦è·¨ç­–ç•¥åˆ†æ
      steps[3].status = 'in_progress';
      steps[3].message = 'éœ€è¦æ·±åº¦åˆ†æï¼Œæ­£åœ¨ä½¿ç”¨ Pro æ¡£ä½é‡æ–°åˆ†æ...';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
      
      // Proå¤ç®—
      const gPro = await generateJson<Record<string, unknown>>(prompt, { 
        maxOutputTokens: 65536, 
        temperature: 0.4 
      }, 'Pro');
      
      if (!gPro.ok) {
        steps[3].status = 'error';
        controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
        sendErrorSafe('QA', 'Proæ·±åº¦åˆ†æåä»æ— æ³•é€šè¿‡è´¨é‡æ£€æŸ¥');
        throw new Error('QA');
      }
      
      const analysisDataPro = gPro.data;
      const s4Pro = AnalyzeProgressSchema.safeParse(analysisDataPro);
      if (!s4Pro.success) {
        steps[3].status = 'error';
        controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
        sendErrorSafe('SCHEMA', 'Proæ·±åº¦åˆ†æåSchemaéªŒè¯å¤±è´¥', traceId);
        throw new Error('SCHEMA');
      }
      
      // é‡æ–°æ£€æŸ¥Proç»“æœçš„QA
      const s4qaPro = runQualityGates('S4', analysisDataPro, { strategyMetrics: payload.userContext.strategySpec?.metrics || [] });
      if (!s4qaPro.passed) {
        steps[3].status = 'error';
        controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
        sendErrorSafe('QA', 'Proæ·±åº¦åˆ†æåä»æ— æ³•é€šè¿‡è´¨é‡æ£€æŸ¥');
        throw new Error('QA');
      }
      
      // ä½¿ç”¨Proåˆ†æç»“æœ
      analysisData = analysisDataPro;
    }

    await new Promise(resolve => setTimeout(resolve, 500));
    steps[3].status = 'completed';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    // T8: è®°å½•S4å¯è§‚æµ‹æ€§ä¿¡æ¯
    const wasProUsed = !s4qa.passed; // å¦‚æœQAå¤±è´¥ï¼Œè¯´æ˜ä½¿ç”¨äº†Pro
    logger.info('S4 Analysis completed', {
      traceId,
      tier_used: wasProUsed ? 'Pro' : 'Lite',
      qa_passed: s4qa.passed,
      auto_repair_applied: wasProUsed
    });

    controller.enqueue(encoder.encode(createStreamMessage('data_structure', {
      status: 'success',
      data: analysisData,
      traceId
    })));
    
  } catch (error) {
    steps.forEach(s => { if (s.status === 'in_progress') s.status = 'error'; });
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    throw error;
  } finally {
    clearInterval(hb);
  }
}

async function handleConsultStream(
  controller: ReadableStreamDefaultController<Uint8Array>,
  encoder: TextEncoder,
  payload: ConsultPayload
) {
  const steps = getCognitiveSteps('consult');
  
  controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { 
    steps: steps.map(s => ({ ...s, status: 'pending' }))
  })));

  const genAI = createGeminiClient();
  
  if (!genAI) {
    // æ¨¡æ‹Ÿå¤„ç†
    for (let i = 0; i < steps.length; i++) {
      steps[i].status = 'in_progress';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
      await new Promise(resolve => setTimeout(resolve, 600 + Math.random() * 600));
      steps[i].status = 'completed';
      controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    }

    const response = 'è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ã€‚è®©æˆ‘åŸºäºæ‚¨çš„å­¦ä¹ å†ç¨‹æ¥å›ç­”...';
    
    controller.enqueue(encoder.encode(createStreamMessage('data_structure', {
      status: 'success',
      data: { response }
    })));
    return;
  }

  try {
    steps[0].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    
    const frameworkSummary = payload.userContext.knowledgeFramework?.map(node => 
      `${node.title}: ${node.summary}`
    ).join('; ') || 'æ— ';
    
    const completedActions = payload.userContext.actionPlan?.filter(item => item.isCompleted).length || 0;
    const totalActions = payload.userContext.actionPlan?.length || 0;
    
    await new Promise(resolve => setTimeout(resolve, 800));
    steps[0].status = 'completed';
    steps[1].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    const prompt = `ä½œä¸ºä¸€åä¸“ä¸šçš„è®¤çŸ¥æ•™ç»ƒå’Œå­¦ä¹ é¡¾é—®ï¼Œè¯·å›ç­”å­¦ä¹ è€…çš„é—®é¢˜ã€‚

å­¦ä¹ è€…èƒŒæ™¯ï¼š
- å­¦ä¹ ç›®æ ‡ï¼š${payload.userContext.userGoal}
- çŸ¥è¯†æ¡†æ¶ï¼š${frameworkSummary}
- è¡ŒåŠ¨è®¡åˆ’è¿›åº¦ï¼š${completedActions}/${totalActions} å·²å®Œæˆ
- å­¦ä¹ æ¯”å–»ï¼š${payload.userContext.systemDynamics?.metaphor || 'æ— '}

å­¦ä¹ è€…çš„é—®é¢˜ï¼š${payload.question}

è¯·æä¾›ï¼š
1. ç›´æ¥å›ç­”é—®é¢˜
2. ç»“åˆå­¦ä¹ è€…çš„å…·ä½“æƒ…å†µå’Œè¿›åº¦
3. æä¾›å®ç”¨çš„æŒ‡å¯¼æˆ–å»ºè®®
4. ä¿æŒåœ¨å­¦ä¹ ç›®æ ‡çš„èŒƒå›´å†…

è¦æ±‚ï¼š
- å›ç­”è¦å…·ä½“ã€å®ç”¨ã€æœ‰é’ˆå¯¹æ€§
- è¯­æ°”è¦å‹å¥½ã€æ”¯æŒå’Œé¼“åŠ±
- é•¿åº¦æ§åˆ¶åœ¨150-300å­—
- ä½¿ç”¨ç®€ä½“ä¸­æ–‡
- å¦‚æœé—®é¢˜è¶…å‡ºå­¦ä¹ ç›®æ ‡èŒƒå›´ï¼Œç¤¼è²Œåœ°å¼•å¯¼å›åˆ°ä¸»é¢˜

è¯·ç›´æ¥è¿”å›ä½ çš„å›ç­”å†…å®¹ï¼ˆçº¯æ–‡æœ¬ï¼Œä¸éœ€è¦JSONæ ¼å¼ï¼‰ã€‚`;

    await new Promise(resolve => setTimeout(resolve, 800));
    steps[1].status = 'completed';
    steps[2].status = 'in_progress';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    const g = await generateText(prompt, { maxOutputTokens: 65536, temperature: 0.8 }, 'Pro');

    await new Promise(resolve => setTimeout(resolve, 500));
    steps[2].status = 'completed';
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));

    if (!g.ok) {
      throw new Error('Failed to get consultation response');
    }

    controller.enqueue(encoder.encode(createStreamMessage('data_structure', {
      status: 'success', 
      data: { response: g.text }
    })));
    
  } catch (error) {
    steps.forEach(s => { if (s.status === 'in_progress') s.status = 'error'; });
    controller.enqueue(encoder.encode(createStreamMessage('cognitive_step', { steps })));
    throw error;
  }
}
